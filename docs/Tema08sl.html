<!DOCTYPE html>
<html>
<head>
  <title>Tema 08 - Aprendizaje Estadístico</title>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Tema 08 - Aprendizaje Estadístico',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: 'Tema08sl_files/logo.svg',
              },

      // Author information
      presenters: [
            {
        name:  'Prof.: Pedro Albarrán' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            {
        name:  'Prof.: Alberto Pérez' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>
  <script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
  <link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }
/* https://github.com/ropensci/plotly/pull/524#issuecomment-468142578 */
slide:not(.current) .plotly.html-widget{
  display: block;
}

    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
            code.sourceCode > span { display: inline-block; line-height: 1.25; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode { white-space: pre; position: relative; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    code.sourceCode { white-space: pre-wrap; }
    code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
        
    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(Tema08sl_files/logo.svg) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>


</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="Tema08sl_files/logo.svg"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      
      <p data-config-presenter><!-- populated from slide_config.json --></p>
            <p style="margin-top: 6px; margin-left: -2px;">Universidad de Alicante, Curso 2020/21</p>
          </hgroup>
  </slide>

<slide class=""><hgroup><h2>Aprendizaje Estadístico o Automático</h2></hgroup><article  id="aprendizaje-estadístico-o-automático">

<ul>
<li>Aprendizaje automático (<em>machine learning</em>, ML) o estadístico (<em>statiscal learning</em>): conjunto de técnicas algorítmicas para extraer información de los datos</li>
</ul>

<center>

<img width="65%" src='pic/ML2.jpg' title=''/>

</center>

</article></slide><slide class=""><hgroup><h2>Aprendizaje supervisado vs. no supervisado</h2></hgroup><article  id="aprendizaje-supervisado-vs.-no-supervisado">

<ul>
<li><p><strong>Aprendizaje supervisado</strong>: escenarios en los que para cada observación de las mediciones \(X_i\) hay una <em>respuesta asociada</em> \(Y_i\) (&ldquo;supervisa&rdquo; el aprendizaje)</p>

<ul>
<li>Aprendemos la respuesta de casos nuevos a partir de casos previos</li>
</ul></li>
</ul>

<center>

<img width="55%" src='pic/imgSuper-Unsuper.png' title=''/>

</center>

<ul>
<li><p><strong>Aprendizaje no supervisado</strong>: no hay una respuesta asociada a las mediciones de \(X_i\) para supervisar el análisis que generará un modelo.</p>

<ul>
<li>Aprendemos rasgos no medidos a partir de casos &ldquo;no etiquetados&rdquo;: ej. observaciones similares organizadas en grupos distintos <!--(de clientes, países)--></li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Aprendizaje supervisado</h2></hgroup><article  id="aprendizaje-supervisado">

<ul>
<li><p>Modelo para la variable dependiente (de respuesta) en función de factores observados (predictores/características), más otros no observados (\(\varepsilon\)) \[
Y = f(X) + \varepsilon
\]</p>

<p><!--Y= variable objetivo)--> <!--X= independientes (predictores, características, regresores, factores)--> <!--X= inputs, features, covariates --></p>

<ul>
<li>\(f\) representa la información/relación sistemática que \(X\) (género, educación, etc.) ofrecen sobre un resultado medido \(Y\) (ej. renta)</li>
</ul></li>
<li><p>Objetivos:</p>

<ul>
<li><p>predecir casos <em>nuevos</em> <!-- a partir de otros previamente etiquetados  (medidos/clasificados)--></p></li>
<li><p>comprender qué factores afectan al resultado y cómo</p></li>
<li><p>evaluar la calidad de nuestras predicciones e inferencias</p></li>
</ul></li>
<li><p>Cuidado con afirmaciones sobre <em>causalidad</em>!</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Aprendizaje supervisado: estimar \(f\) desconocida</h2></hgroup><article  id="aprendizaje-supervisado-estimar-f-desconocida">

<ul>
<li><p><strong>Modelo paramétrico:</strong> supone un forma de \(f\) que depende de parámetros desconocidos, p.e., lineal \(f(x) =\beta_0 + \beta_1 x_1 + \dots + \beta_k x_k\)</p></li>
<li><p><strong>Modelo no paramétrico:</strong> ajustar \(f\) a los datos sin supuestos funcionales</p>

<ul>
<li>Es más sencillo estimar parámetros que una función arbitraria</li>
</ul></li>
<li><p>A mayor flexibilidad, mejor ajuste, PERO existe una disyuntiva entre precisión de la predicción e <strong>interpretabilidad</strong> (inferencia)</p></li>
</ul>

<!--
* A veces solo nos interesa predecir el resultado a partir de unos factores
-->

<ul>
<li><p>Preferimos un método más restrictivo si no solo interesa predecir, sino <em>entender</em> la manera en que \(X\) afecta a \(Y\)</p>

<ul>
<li>variables relevantes y su signo y magnitud,</li>
<li>generar hipótesis, etc.</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Problemas de &ldquo;regresión&rdquo; y de clasificación</h2></hgroup><article  id="problemas-de-regresión-y-de-clasificación">

<ul>
<li>El método de aprendizaje supervisado más adecuado para un problema depende de si la respuesta es cualitativa o cuantitativa.</li>
</ul>

<ol>
<li><p><strong>Problema de Regresión</strong></p>

<ul>
<li>La variable de respuesta es cuantitativa (toma valores numéricos)</li>
</ul></li>
<li><p><strong>Problema de Clasificación</strong></p>

<ul>
<li>La variable de respuesta es cualitativa (toma valores en una de \(C\) categorías o clases)</li>
</ul></li>
</ol>

<!--
No trataremos todas las técnicas ni podemos entrar en el fondo de cada técnica.  

El objetivo es proporcionar una visión general de alto nivel de las técnicas y modelos empleados habitualmente y así comprender los objetivos generales del aprendizaje automático.
-->

</article></slide><slide class=""><hgroup><h2>Ejemplo de regresión</h2></hgroup><article  id="ejemplo-de-regresión">

<ul>
<li>Predecir el número de usuarios (<code>volume</code>):</li>
</ul>

<pre class = 'prettyprint lang-r'>library(mosaicData)
RailTrail %&gt;% ggplot(aes(x = avgtemp, y = volume)) + 
  geom_point() + geom_smooth(method = &#39;lm&#39;, formula = y ~ poly(x,3) ) +
  coord_cartesian(ylim = c(100,750))</pre>

<ul>
<li><p><code>volume</code> &ldquo;supervisa&rdquo; el ajuste del modelo</p></li>
<li><p>Podemos usar el modelo para predecir <code>volume</code></p></li>
</ul>

<pre class = 'prettyprint lang-r'>RailTrail.fit &lt;- RailTrail %&gt;% 
  mutate(
    lm.fit = lm(volume ~ poly(avgtemp,2), data = .)$fitted) 
head(select(RailTrail.fit, volume, lm.fit, avgtemp))</pre>

<!--
## Ejemplo de clasificación

* Clasificación del tipo de flor en los [datos Iris](https://es.wikipedia.org/wiki/Iris_flor_conjunto_de_datos)


```r
iris %>% ggplot(aes(x = Petal.Length, y = Species, color = Species))  +
  geom_point()
```

* Clasificación rudimentaria en función de longitud del pétalo:

  * Setosa, si < 2 
    
  * Versicolor, si >2 y <5
  
  * Virginica, si > 5
     



* La predicción es mucho mejor si se utilizan más variables


* La visualización tiene un poder limitado: debemos usar métodos de clasificación basados en modelos o algoritmos.

-->

</article></slide><slide class=""><hgroup><h2>Ejemplo de clasificación</h2></hgroup><article  id="ejemplo-de-clasificación">

<ul>
<li>Factores para predecir si un cliente potencial es de alto ingreso</li>
</ul>

<pre class = 'prettyprint lang-r'>censo &lt;- read_csv(&quot;https://www.dropbox.com/s/6bqyjnkd2c638rm/census.csv?dl=1&quot;) %&gt;%
  mutate(income = as.integer(factor(income))-1)</pre>

<ul>
<li>Ajustamos un modelo logístico (logit) simple</li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_logistico &lt;- glm(income ~ capital_gain, data = censo, family = &quot;binomial&quot;)
summary(modelo_logistico)
cbind(censo$income, predict(modelo_logistico, type = &quot;response&quot;)) %&gt;% head()</pre>

<ul>
<li>La predicción mejora si incluimos más variables explicativas (modelo más flexible)</li>
</ul>

<!--

-->

<!--
## Ejemplo de aprendizaje no supervisado

<!--
Usamos técnicas en el aprendizaje no supervisado cuando no hay ninguna variable de respuesta. Simplemente tenemos un conjunto de observaciones $X$, y queremos entender las relaciones entre ellos.
-->

<!--

* *Clustering*  (agrupamiento o particionamiento): identificar grupos desconocidos de casos a partir de características observadas

<!--
Tiempo de espera entre erupciones y sobre duración de la erupción para el géiser Old Faithful en el Parque Nacional de Yellowstone, EE.UU.

![https://en.wikipedia.org/wiki/Old_Faithful](pic/OldFaithful1948.jpg)
-->

<!--
* Tiempo de espera entre erupciones y sobre duración de la erupción para el géiser Old Faithful




```r
faithful%>% ggplot(aes(y = eruptions, x = waiting)) + 
  geom_point()
```

* Se pueden apreciar dos "grupos" o *clusters* o tipos de erupciones.


```r
faithful.clustered <- 
  faithful %>% mutate(cluster = factor(kmeans(x = ., centers = 2)$cluster))
faithful.clustered %>% ggplot(aes(y = eruptions, x = waiting)) + 
  geom_point(aes(color = cluster))
```

-->

</article></slide><slide class=""><hgroup><h2>Error de predicción</h2></hgroup><article  id="error-de-predicción">

<ul>
<li><p>Un modelo es mejor si sus predicciones se ajusten mejor a las observaciones</p></li>
<li><p>El error de predicción es \(y - \widehat{y} = f(X) - \widehat{f}(X) + \varepsilon\)</p>

<ul>
<li><p>\(f - \widehat{f}\) = error reducible (eligiendo modelo)</p></li>
<li><p>\(\varepsilon\) = error irreducible (variables no observadas)</p></li>
</ul></li>
<li><p>La <strong>función de pérdida (o coste)</strong> evalúa cómo valoramos las desviaciones <img src="Tema08sl_files/figure-html/figures-side-1.png" width="50%" /><img src="Tema08sl_files/figure-html/figures-side-2.png" width="50%" /></p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Métricas de error de predicción (cuantitativa)</h2></hgroup><article  id="métricas-de-error-de-predicción-cuantitativa">

<ul>
<li><em>Mean Square Error</em>: \(MSE(y,\widehat{y})={\frac{1}{n}\sum_{i=1}^{n}\left(y-\widehat{y}\right)^2}\)

<ul>
<li>penaliza grandes desviaciones</li>
</ul></li>
<li><em>Root Mean Square Error</em>: \(RMSE(y,\widehat{y})=\sqrt{\frac{1}{n}\sum_{i=1}^{n}\left(y-\widehat{y}\right)^2}\)

<ul>
<li>mismas unidades que \(y\)</li>
</ul></li>
<li><em>Mean Absolute Error</em>: \(MAE(y,\widehat{y})=\frac{1}{n}\sum_{i=1}^{n}\left|y-\widehat{y}\right|\)</li>
</ul>

<!--     + también mediana -->

<ul>
<li><em>Correlación</em> lineal o de rangos entre \(y\) y \(\widehat{y}\)</li>
</ul>

<p><!--
      + lineal ($y$ y $\widehat{y}$ pueden no tener las mismas unidades y escala como con RMSE y MAE) 
      + de rangos ($y$ y $\widehat{y}$ solo tiene que tener el mismo orden relativo, no minimizar distancia entre ellas)
--></p>

<ul>
<li><p><em>Coeficiente de determinación</em>, \(R^2\), y \(R^2-ajustado\) <!--(solo para comparar modelos con la misma variable dependiente)--></p></li>
<li><p>\(AIC\), \(BIC\), …</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Muestras de entrenamiento y de prueba</h2></hgroup><article  id="muestras-de-entrenamiento-y-de-prueba">

<ul>
<li><p>Las métricas de error (ej., \(MSE\)) se calculan habitualmente para los mismos datos usados para ajustar/estimar el modelo: <strong>muestra de entrenamiento</strong></p></li>
<li><p>PERO nosotros queremos saber qué tal se predicen <em>casos nuevos</em></p></li>
<li><p>Usar las métricas en muestras de entrenamiento lleva a problemas de <strong>&ldquo;overfitting&rdquo;</strong> (sobreajuste): escenarios en los que un modelo menos flexible tendría menor error de predicción con casos nuevos</p>

<ul>
<li>Los grados de libertad (número de valores en el modelo que son libres de variar) resume la <em>flexibilidad</em> de una curva.</li>
</ul></li>
<li><p>Debemos calcular las métricas de error con observaciones que el modelo NO ha usado antes: <strong>muestra de prueba</strong></p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>&ldquo;Overfitting&rdquo;</h2></hgroup><article  id="overfitting">

<center>

<img width="85%" src='pic/overfitting01b.png' title=''/>

</center>

<pre class = 'prettyprint lang-r'>RailTrail %&gt;% ggplot(aes(x = avgtemp, y = volume)) + 
  geom_point() + geom_smooth(method = &#39;lm&#39;, formula = y ~ poly(x,22) ) +
  coord_cartesian(ylim = c(100,750))</pre>

</article></slide><slide class=""><hgroup><h2>&ldquo;Overfitting&rdquo; (cont.)</h2></hgroup><article  id="overfitting-cont.">

<div style="display: flex;">
<div>
<img width="99%" src='pic/overfitting2n.png' title=''/></div>

<div>
<p>  </p></div>

<div>
<img width="99%" src='pic/overfitting3n.png' title=''/></div></div>

<!--
* Independientemente de los datos y método, a medida que aumenta la flexibilidad 
-->

<ul>
<li>Siempre que aumenta la flexibilidad el MSE

<ul>
<li><p>disminuye en la muestra de entrenamiento</p></li>
<li><p>tiene forma de U en la muestra de prueba</p></li>
</ul></li>
<li>Nota: el MSE en entrenamiento es siempre menor que en prueba</li>
</ul>

</article></slide><slide class=""><hgroup><h2>MSE en la muestra de prueba</h2></hgroup><article  id="mse-en-la-muestra-de-prueba">

<p>\[
\small
E\left[\left(y-\widehat{f}(x)\right)^2\right] =
E\left[\left(f(x)-\widehat{f}(x) + \varepsilon 
+ E\left[\widehat{f}(x)\right]-E\left[\widehat{f}(x)\right] \right)^2\right] =
\]</p>

<p>\[
\small
=\underbrace{\left[E\left(\widehat{f}(x)\right)-f(x)\right]^2}_{(1)} + \underbrace{E\left(\left[\widehat{f}(x)-E\left(\widehat{f}(x)\right)\right]^2\right)}_{(2)}+Var(\varepsilon)
\]</p>

<ul>
<li><p>\(\small (1)=\left[Sesgo\left(\widehat{f}(x)\right)\right]^2\): error por supuestos erróneos en \(f\)</p>

<ul>
<li>ajuste insuficiente (<em>underfit</em>) al perder relaciones relevantes entre \(X\) e \(Y\)</li>
</ul></li>
<li><p>\(\small (2)=Var\left(\widehat{f}(x)\right)\): sensibilidad a fluctuaciones en el entrenamiento</p>

<ul>
<li>si el algoritmo modela puro ruido en entrenamiento, ajustará bien allí, pero predecirá mal casos nuevos (<em>overfit</em>)</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>&ldquo;Trade-off&rdquo; Varianza–Sesgo</h2></hgroup><article  id="trade-off-varianzasesgo">

<ul>
<li>El sesgo se reduce y la varianza aumenta con la complejidad del modelo</li>
</ul>

<!--
A medida que se añaden más y más parámetros a un modelo, la complejidad del modelo aumenta y la varianza se convierte en nuestra principal preocupación, mientras que el sesgo disminuye constantemente. Por ejemplo, a medida que se añaden más términos polinómicos a una regresión lineal, mayor será la complejidad del modelo resultante. 
-->

<center>

<img width="95%" src='pic/biasvariance-tradeoff.png' title=''/>

</center>

<!--
SESGO-VARIANZA VISTO EN ECONOMETRIA I: omitir variable relevante (modelos menos flexible), crea sesgo.
                                       incluir variable no relevante (mas flexibe), aumenta varianza
-->

</article></slide><slide class=""><hgroup><h2>&ldquo;Trade-off&rdquo; Varianza–Sesgo (cont.)</h2></hgroup><article  id="trade-off-varianzasesgo-cont.">

<ul>
<li><p>Es fácil construir un modelo con bajo sesgo, pero tendrá alta varianza. Y al revés.</p></li>
<li><p>El desafío es encontrar un método (ej., flexibilidad del modelo) para el cual tanto la varianza como el sesgo cuadrado sean bajos</p></li>
<li><p>NO es posible minimizar simultáneamente ambas fuentes de error: <em>memorización</em> (en entrenamiento) vs. <em>generalización</em> de resultados</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Medir el Error en la Clasificación</h2></hgroup><article  id="medir-el-error-en-la-clasificación">

<ul>
<li><p>Los modelos de clasificación NO predicen directamente la categoría, sino la <em>probabilidad</em> de que una observación pertenezca a cada categoría</p></li>
<li><p>Típicamente se asigna la clase predicha como aquella con mayor probabilidad: en el caso binario, fijar un umbral de 0.5</p></li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_logistico &lt;- glm(income ~ capital_gain, data = censo, family = &quot;binomial&quot;)
prob.predict &lt;- predict(modelo_logistico, type = &quot;response&quot;)

umbral &lt;- 0.5

cat.predict  &lt;- if_else(prob.predict &gt; umbral, 1, 0) 
cbind(censo$income, cat.predict, prob.predict) %&gt;% head(10)</pre>

<ul>
<li>Como no tiene sentido diferencia de clases (variables categóricas), NO se pueden calcular medidas como el MSE y otros relacionados</li>
</ul>

<!--
* Existen pseudo-$\small R^2$ como la correlación al cuadrado entre 

-->

</article></slide><slide class=""><hgroup><h2>Matriz de Confusión</h2></hgroup><article  id="matriz-de-confusión">

<ul>
<li><strong>Matriz de confusión</strong>: tabulación de los categorías observadas frente a las categorías predichas</li>
</ul>

<table class=" lightable-paper lightable-striped" style='font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>

<thead>

<tr>

<th style="empty-cells: hide;" colspan="1">

</th>

<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; font-size: x-large;" colspan="2">

<div style="TRUE">
CLASE OBSERVADA</div>

</th>

</tr>

<tr>

<th style="text-align:center;">

.

</th>

<th style="text-align:center;">

POSITIVO (1)

</th>

<th style="text-align:center;">

NEGATIVO (0)

</th>

</tr>

</thead>

<tbody>

<tr grouplength="4">

<td colspan="3" style="border-bottom: 1px solid;">

<strong>CLASE PREDICHA</strong>

</td>

</tr>

<tr>

<td style="text-align:center;vertical-align: middle !important; padding-left:  2em;" rowspan="2" indentlevel="1">

POSITIVO (1)

</td>

<td style="text-align:center;">

Verdadero Positivo [VP]

</td>

<td style="text-align:center;">

Falso Positivo [FP]

</td>

</tr>

<tr>

<td style="text-align:center; padding-left:  2em;" indentlevel="1">

</td>

<td style="text-align:center;">

(Error Tipo I)

</td>

</tr>

<tr>

<td style="text-align:center;vertical-align: middle !important; padding-left:  2em;" rowspan="2" indentlevel="1">

NEGATIVO (0)

</td>

<td style="text-align:center;">

Falso Negativo [FN]

</td>

<td style="text-align:center;">

Verdadero Negativo [VN]

</td>

</tr>

<tr>

<td style="text-align:center; padding-left:  2em;" indentlevel="1">

(Error Tipo II)

</td>

<td style="text-align:center;">

</td>

</tr>

</tbody>

</table>

<!--
* Ver [aquí](https://en.wikipedia.org/wiki/Confusion_matrix)
-->

<pre class = 'prettyprint lang-r'>table(cat.predict, censo$income)</pre>

<!--
## Métricas calculadas con la matriz de confusión
-->

</article></slide><slide class=""><hgroup><h2>Métricas con la matriz de confusión</h2></hgroup><article  id="métricas-con-la-matriz-de-confusión">

<ul>
<li><p><strong>Tasa de error en la clasificación o de clasificación errónea</strong>: \[
\small TCE=\frac{FP+FN}{VP+FP+VN+FN} = \frac{1}{n}\sum_{i=1}^{n}I\left[y_i \neq \widehat{y}_i\right]
\]</p>

<ul>
<li>su complemento es la tasa de observaciones correctamente clasificadas (exactitud o <em>accuracy</em>) \(\small ACCUR=(VP+VN)/(VP+FP+VN+FN)\)</li>
</ul></li>
<li><p>Puede no ser informativa cuando algunas clases son infrecuentes (datos <em>imbalanced</em> o desequilibrados): ej., TCE será baja porque la mayoría de las observaciones no son fraude</p></li>
<li><p>La <strong>precisión</strong> o valor de predicción positivo es la cantidad de verdaderos positivos sobre el total de positivos predichos \(\small PREC=VP/(VP+FP)\)</p>

<ul>
<li>Tasa de falso descubrimiento: \(\small 1-PREC\)</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Métricas con la matriz de confusión (cont.)</h2></hgroup><article  id="métricas-con-la-matriz-de-confusión-cont.">

<ul>
<li>La <strong>tasa de verdaderos positivos</strong>, <strong>sensibilidad</strong> o exahustividad (<em>recall</em>) es la cantidad de verdaderos positivos sobre el total de positivos observados \[
\small TVP=SENSIT=VP/(VP+FN)
\]</li>
</ul>

<!-- probabilidad de detección, potencia  -->

<ul>
<li><p>La <strong>tasa de verdaderos negativos</strong> o <em>especificidad</em> es la cantidad de verdaderos negativos sobre el total de negativos observados \[
\small TVN=ESPECIF=VN/(VN+FP)
\]</p>

<ul>
<li><strong>Tasa de falsos positivos</strong>: \(\small TFP = 1 - TVN = 1 - ESPECIF\)</li>
</ul></li>
<li><p>Existen varias otras medidas derivadas de las anteriores</p></li>
<li><p>Una medida global para datos <em>imbalanced</em> es la <em>exactitud equilibrada</em>: \(\small \frac{TVP+TVN}{2}\)</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Curva ROC y AUC</h2></hgroup><article  id="curva-roc-y-auc">

<!--
https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc
-->

<ul>
<li>La <strong>curva ROC</strong> (&ldquo;receiver operating characteristic&rdquo;) representa TVP (eje y) frente a TFP (eje x) en <em>diferentes umbrales de clasificación</em></li>
</ul>

<!--(es una curva de probabilidad)-->

<ul>
<li>Reducir el umbral clasifica más elementos como positivos, por lo que aumentan tanto los falsos positivos como los verdaderos positivos.</li>
</ul>

<div style="display: flex;">
<div>
<center>

<img width="65%" src='pic/ROC-AUC.svg' title=''/>

</center></div>

<div>
<ul>
<li><p>Deberíamos evaluar cada modelo con muchos umbrales</p></li>
<li><p>El área bajo la curva ROC es la <strong>AUC</strong> (&ldquo;area under the curve&rdquo;)</p></li>
</ul></div></div>

<ul>
<li><strong>AUC - ROC</strong> es una medida de rendimiento para problemas de clasificación para diferentes umbrales</li>
</ul>

<!--
![](pic/ROCCurve.svg){width=40%}
![](pic/AUC.svg){width=40%}

https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/

https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
-->

</article></slide><slide class=""><hgroup><h2>Curva ROC y AUC (cont.)</h2></hgroup><article  id="curva-roc-y-auc-cont.">

<ul>
<li>AUC informa del grado de separabilidad: mayor AUC implica que el modelo es capaz de distinguir entre clases (predecir 0s y 1s correctamente)</li>
</ul>

<center>

<img width="55%" src='pic/ROC.png' title=''/>

</center>

</article></slide><slide class=""><hgroup><h2>Curva ROC y AUC: extensiones</h2></hgroup><article  id="curva-roc-y-auc-extensiones">

<ul>
<li><p>Cuando la variable de respuesta tiene más de dos clases,</p>

<ol>
<li><p>Se realiza un análisis AUC-ROC para cada categoría: se define unavariable binaria para la categoría frente a todas las demás</p></li>
<li><p>Se obtiene el promedio de tanto de la ROC como de la AUC, bien dando igual peso a cada categoría o bien ponderando el número de casos de cada una</p></li>
</ol></li>
<li><p>Con datos <em>imbalanced</em> algunos autores señalan que es más informativo usar gráfico de TFP frente a precisión en lugar de ROC</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Evaluación de Modelos: entrenamiento y prueba</h2></hgroup><article  id="evaluación-de-modelos-entrenamiento-y-prueba">

<ul>
<li><p>Para evaluar correctamente los modelos, DEBEMOS <strong>dividir aleatoriamente</strong> el conjunto de datos disponible en dos partes:</p>

<ul>
<li><p><strong>Entrenamiento</strong>: conjunto de datos sobre los que se construye/estima el modelo</p></li>
<li><p><strong>Pruebas</strong>: se comprueba cómo funciona un modelo ya construido, evaluándolo con datos no vistos anteriormente</p></li>
</ul></li>
<li><p>De esta manera podemos evitar (o al menos minimizar) problemas tanto de <em>underfit</em> como sobre todo <em>overfit</em>.</p></li>
<li><p>La partición típica suele incluir el 80% o 90% de los datos en entrenamiento y el 10% o 20% en prueba</p></li>
<li><p>¿Por qué renunciar a parte de los datos si sabemos que un tamaño muestral grande es importante? Evaluar correctamente un modelo lo es mucho más</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Evaluación de Modelos: Validación cruzada</h2></hgroup><article  id="evaluación-de-modelos-validación-cruzada">

<!--
* Los resultados de evaluación puede verse afectados por la partición concreta obtenida (ej. incluir observaciones atípicas en la muestra de prueba)
-->

<ul>
<li>La técnica más usada se llama de validación cruzada (<em>cross-validation</em> o <em>rotation estimation</em>).

<ul>
<li>se repite varias veces y de forma ordenada el proceso de remuestreo para la partición en grupos de entrenamiento y prueba (similar a <em>bootstrap</em>)</li>
<li>se evita que los resultados sean sensibles a una partición concreta</li>
</ul></li>
</ul>

<!--
the estimate of test error is highlyvariable, depending on precisely which observations areincluded in the training set and which observations areincluded in the validation set.•In the validation approach, only a subset of theobservations — those that are included in the training setrather than in the validation set — are used to fit themodel.•This suggests that the validation set error may tend tooverestimatethe test error for the model fit on the entiredata set
-->

<ul>
<li><p>Entre las variantes más habituales se encuentran:</p>

<ul>
<li><p>Validación cruzada de K iteraciones (<em>K-fold cross-validation</em> o K-fold CV)</p></li>
<li><p>Validación cruzada aleatoria (<em>Random cross-validation</em>, RCV)</p></li>
<li><p>Validación cruzada dejando uno fuera (<em>Leave-one-out cross-validation</em>, LOOCV)</p></li>
<li><p>Validación cruzada dejando p fuera (<em>Leave-p-out cross-validation</em>, LpOCV)</p></li>
</ul></li>
</ul>

<!--
https://en.wikipedia.org/wiki/Cross-validation_(statistics)
-->

</article></slide><slide class=""><hgroup><h2>Validación cruzada de K iteraciones</h2></hgroup><article  id="validación-cruzada-de-k-iteraciones">

<ul>
<li>La <strong>validación cruzada de K iteraciones</strong> divide (aleatoriamente y <em>ex-ante</em>) la muestra en K subconjuntos (normalmente 10)</li>
</ul>

<div style="display: flex;">
<div>
<center>

<img src='pic/K-fold_cross_validation.jpg' title='fig:'/>

</center></div>

<div>
<ul>
<li><p>Un subconjunto se usa como prueba y el K-1 restantes como entrenamiento</p></li>
<li><p>Se repite el proceso durante k iteraciones, con cada posible subconjunto de datos de prueba.</p></li>
</ul></div></div>

<ul>
<li><p>Se calcula la media aritmética de los resultados de cada iteración para obtener un único resultado</p></li>
<li><p>Es el tipo más habitual de validación cruzada</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Validación cruzada aleatoria y LOOCV</h2></hgroup><article  id="validación-cruzada-aleatoria-y-loocv">

<div style="display: flex;">
<div>
<center>

<img src='pic/Random_cross_validation.jpg' title=''/>

</center></div>

<div>
<ul>
<li><p><strong>RCV</strong>: en <em>cada iteración</em> se realiza la particion aleatoria (con reemplazamiento) entre entrenamiento y prueba</p></li>
<li><p>Las observaciones pueden &ldquo;repetir&rdquo; como prueba</p></li>
</ul></div></div>

<div style="display: flex;">
<div>
<center>

<img src='pic/Leave-one-out.jpg' title=''/>

</center></div>

<div>
<ul>
<li><p><strong>LOOCV</strong>: solo una observación se usa como prueba en cada iteración y el resto como entrenamiento</p></li>
<li><p>Se realizan \(n\) iteraciones; se calcula una media sobre \(n\) resultados</p></li>
</ul></div></div></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
