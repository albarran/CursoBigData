<!DOCTYPE html>
<html>
<head>
  <title>Tema 09 - Regresión Lineal</title>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Tema 09 - Regresión Lineal',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: 'Tema09sl_files/logo.svg',
              },

      // Author information
      presenters: [
            {
        name:  'Prof.: Pedro Albarrán' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            {
        name:  'Prof.: Alberto Pérez' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }
/* https://github.com/ropensci/plotly/pull/524#issuecomment-468142578 */
slide:not(.current) .plotly.html-widget{
  display: block;
}

    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
            code.sourceCode > span { display: inline-block; line-height: 1.25; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode { white-space: pre; position: relative; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    code.sourceCode { white-space: pre-wrap; }
    code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
        
    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(Tema09sl_files/logo.svg) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>


</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="Tema09sl_files/logo.svg"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      
      <p data-config-presenter><!-- populated from slide_config.json --></p>
            <p style="margin-top: 6px; margin-left: -2px;">Universidad de Alicante, Curso 2020/21</p>
          </hgroup>
  </slide>

<!--
## Regresión Lineal Simple
-->

<slide class=""><hgroup><h2>Regresión Lineal</h2></hgroup><article  id="regresión-lineal">

<ul>
<li><p>La regresión lineal predice una respuesta cuantitativa \(\small Y\) como a partir de \(k\) regresores \(X=\) \(\small X_1,X_2,\dots,X_k\)</p></li>
<li><p>Supuesto<!-- de linealidad (en los parámetros)-->: relación lineal entre \(\small X\) e \(\small Y\) \[
\small
Y=\beta_0+\beta_1 X_1+ \dots + \beta_k X_p + \varepsilon
\]</p></li>
<li><p>Los coeficientes o parámetros del modelo representan</p>

<ul>
<li><p>\(\small \beta_0\) (constante): valor esperado de \(\small Y\) cuando \(\small X_=X_2=\dots=X_k=0\)</p></li>
<li><p>\(\small \beta_j\) (pendiente de la línea): cambio medio en \(\small Y\) por un incremento de una unidad en \(\small X_j\) (para \(j=1,...,k\)), <em>ceteris paribus</em></p></li>
</ul></li>
<li><p>Objetivo: estimar los coeficientes desconocidos a partir de una muestra</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Regresión Lineal: Estimación</h2></hgroup><article  id="regresión-lineal-estimación">

<ul>
<li><p>El error de estimación o <strong>residuo</strong> es \(\small \hat{e}_i = y_i - \hat{y}_i\), donde la predicción a partir del modelo estimado es \(\small \hat{y}_i=\hat{\beta}_0+\hat{\beta}_1 X_1+ \dots + \hat{\beta}_k X_p\)</p></li>
<li><p>Los coeficientes estimados son los que minimizan la Suma Cuadrática de Residuos: la suma total de distancias entre los datos observados y predichos</p></li>
</ul>

<div style="display: flex;">
<div>
<center>

<img width="100%" src='pic/fig_E2b.jpeg' title=''/>

</center></div>

<div>
<p>\[
\small SCR=\sum_{i=1}^{n} \hat{e}_i^2= \sum_{i=1}^{n} ( y_i - \hat{y}_i)^2
\]</p>

<ul>
<li>Por tanto, también minimiza \(\small MSE = \frac{SCR}{n}\)</li>
</ul></div></div>

<ul>
<li>Esto equivale a las condiciones derivadas de suponer \(\small E(\varepsilon|X)=0\)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Regresión Lineal: Precisión de las estimaciones</h2></hgroup><article  id="regresión-lineal-precisión-de-las-estimaciones">

<ul>
<li>La precisión de los coeficientes estimados se mide con el <strong>error estándar</strong></li>
</ul>

<div style="display: flex;">
<div>
<p>\[
\small se(\widehat{\beta}_j) =  \frac{\sigma^2}{(n-1)S^2_{x_j} (1 - R^2_{j})}
\]</p></div>

<div>
<p>   </p></div>

<div>
<ul>
<li>\(\small \sigma^2=Var(\varepsilon)\), estimada con \(\small \frac{SCR}{n-k-1}\)</li>
<li>\(\small S^2_{x_j}=\frac{\sum (x_{ij}-\bar{x}_j)^2}{n-1}=\)varianza muestral de \(\small X_j\)</li>
<li>\(\small R^2_{j}\) es el \(\small R^2\) de la regresión de \(\small X_j\) sobre el resto de regresores</li>
</ul>

<!-- \frac{\sigma^2}{SCT_j (1 - R^2_{j})} = --></div></div>

<ul>
<li><p>Los errores estándar se usan para construir intervalos de confianza y estadísticos para contrastar hipótesis sobre los parámetros, p.e.,</p>

<ul>
<li>significatividad individual: \(\small H_0: \beta_1=0\) con un estadístico \(\small t=\frac{\widehat{\beta}_1-0}{se(\widehat{\beta}_1)}\)</li>
<li>significatividad conjunta: \(\small H_0: \beta_1=\beta_2=\dots=\beta_k=0\) con un estadístico \(\small F\)</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Regresión Lineal: Precisión del modelo</h2></hgroup><article  id="regresión-lineal-precisión-del-modelo">

<ul>
<li><p>Medición de la precisión del modelo:</p>

<ul>
<li>RMSE o variantes como el error estandar de la regresión, \(\small \sqrt{\frac{SCR}{n-k-1}}\): son medidas absolutas en las mismas unidades que \(Y\)</li>
<li>\(\small R^2=1-\frac{SCR}{SCT} = \frac{SCE}{SCT}\) es una medida relativa: proporción de la varianza explicada por el modelo</li>
</ul></li>
<li><p>Las predicción \(\widehat{y}\) también están sujetas a incertidumbre por la estimación</p>

<ul>
<li>Existen formulas para calcular su error estándar (a partir de la matriz de varianza y covarianza de los coeficientes estimados)</li>
<li>Por tanto, también se puede calcular un intervalo de confianza</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Regresión Lineal: Variables cualitativas</h2></hgroup><article  id="regresión-lineal-variables-cualitativas">

<ul>
<li>Sólo dos valores: se incluye un regresor un indicador binario \(\small D\)

<ul>
<li>la constante recoge el valor esperado de \(\small Y\) para el grupo con \(\small D=0\)</li>
<li>el coeficiente del indicador indica el efecto adicional (respecto al otro grupo) en el valor esperado de \(\small Y\) para el grupo con \(\small D=1\)</li>
</ul></li>
<li>Con varias categorías: se incluyen indicadores binarios para cada clase excepto uno, el grupo de referencia

<ul>
<li>la constante recoge el valor medio de \(\small Y\) para el grupo de referencia</li>
<li>cada coeficiente recoge el efecto adicional sobre \(\small Y\) de su grupo</li>
</ul></li>
</ul>

<pre class = 'prettyprint lang-r'>library(ISLR)
lm(data=Carseats , Sales ~ Urban + ShelveLoc)</pre>

<ul>
<li>Aunque R los genera automáticamente para factores, también se pueden crear con <code>if_else()</code> o con el paquete <code>fastDummies</code></li>
</ul>

<!--
Now, before summarizing this R tutorial, it may be worth mentioning that there are other options to recode categorical data to dummy variables. For instance, we could have used the model.matrix function, the dummies package, and the step_dummy (recipes package).
-->

</article></slide><slide class=""><hgroup><h2>Superando el supuesto de linealidad</h2></hgroup><article  id="superando-el-supuesto-de-linealidad">

<ul>
<li><p>Se pueden incluir transformaciones no lineales de las variables del modelo, como logaritmos o incluir términos polinomiales</p></li>
<li><p>La interpretación del cambio de un regresor sobre \(\small Y\) es diferente</p></li>
</ul>

<pre class = 'prettyprint lang-r'>lm(data=Carseats %&gt;% filter(Sales != 0), log(Sales) ~ poly(Advertising,2))</pre>

<!-- https://stackoverflow.com/questions/24198013/significance-of-i-keyword-in-lm-model-in-r -->

<ul>
<li>Otra forma de permitir no linealidades es discretizando variables continuas: permite efectos &ldquo;escalón&rdquo; diferentes para distintos valores</li>
</ul>

<pre class = 'prettyprint lang-r'>lm(data=Carseats , Sales ~ cut_width(Advertising, 10)) %&gt;% summary()</pre>

</article></slide><slide class=""><hgroup><h2>Superando el supuesto de linealidad (cont.)</h2></hgroup><article  id="superando-el-supuesto-de-linealidad-cont.">

<!--
https://www.econometrics-with-r.org/8-3-interactions-between-independent-variables.html
-->

<ul>
<li>También podemos incluir interacciones entre variables: el efecto de un regresor dependerá de otro regresor</li>
</ul>

<pre class = 'prettyprint lang-r'>lm(data=Carseats , Sales ~ Advertising*Income)</pre>

<ul>
<li><p>Principio jerárquico: al incluir una interacción <em>siempre</em> deben incluirse los factores principales (NO sólo <code>Advertising:Income</code>)</p></li>
<li><p>Cuando interactuamos un regresor continuo y uno binario, permitimos que la pendiente del primero sea diferente para cada grupo</p></li>
</ul>

<pre class = 'prettyprint lang-r'>lm(data=Carseats , Sales ~ (Income + Advertising)*Urban)</pre>

<ul>
<li>La interacción de dos variables binarias tiene una interpretación similar, para el efecto esperado de \(\small Y\)</li>
</ul>

<pre class = 'prettyprint lang-r'>lm(data=Carseats , Sales ~ ShelveLoc*Urban)</pre>

</article></slide><slide class=""><hgroup><h2>&ldquo;Problemas&rdquo; del Modelo de Regresión Lineal</h2></hgroup><article  id="problemas-del-modelo-de-regresión-lineal">

<ul>
<li><p><em>No linealidad</em>: incluir transformaciones no lineales <!--de los regresores o la variable dependiente--></p></li>
<li><p><em>Correlación de los errores</em>: afecta a los errores estándar, no la estimación</p>

<ul>
<li>usar errores estándar robustos o modelizar la dinámica</li>
</ul></li>
<li><p><em>Heterocedasticidad</em>: ídem, usar errores estándar robustos <!-- o pesos --></p>

<ul>
<li>los gráficos de los residuos frente a un regresor o valores predichos: ¿heterocedasticidad o no linealidad? <!--logaritmos o raíz cuadrada cuando hay una amplifiación de los residuos --></li>
</ul></li>
<li><p><em>Outliers</em> en la variable de respuesta o en los regresores <!--: se puede intentar detectar con algunos criterios ("arbitrarios": ej. $\small \left|\frac{\hat{e}_i}{se(\hat{e}_i)}\right|>3$)--></p></li>
<li><p><em>Colinearidad</em>: indica que no es posible separar el efecto de cada regresor: eliminar alguno o recombinarlos</p></li>
<li><p><em>No normalidad</em>: SC</p></li>
<li><p>El único supuesto realmente importante es \(\small E[\varepsilon|X]=0\)</p></li>
</ul>

<!--
    afecta a la varianza del estimador de un coeficiente, pero NO a significatividad conjunta
    + realmente indica que no es posible separar adecuadamente el efecto de varios regresores por separado: eliminar alguno o recombinarlos -->

<!--
  + se suele usar criterios como VIF (*variance inflation factor*=1/(1-R^2_j)$=ratio de la varianza del estimador en regresion multiple / reg. simple) 
  si VIF>5 o 10
-->

</article></slide><slide class=""><hgroup><h2>Selección de variables</h2></hgroup><article  id="selección-de-variables">

<!--
* En el análisis exploratorio, encontramos variables significativamente correlacionadas con la variable de respuesta
-->

<ul>
<li><p>NO se pueden examinar todos los posibles modelos que incluyen combinaciones de los regresores significativamente correlacionados <!--(incluyendo interacciones) --></p></li>
<li><p>Procesos automatizados frecuentemente utilizados:</p>

<ul>
<li><p>Selección hacia adelante (<em>forward selection</em>): añadir uno a uno los regresores más correlacionados <!--(criterio de parada en la mejora de SCR o p-valores.--></p></li>
<li><p>Selección hacia atrás (<em>backward selection</em>): comenzando con todos, se va eliminando el regresor con mayor p-valor <!--(hasta criterio de parada)--></p></li>
<li><p>Selección mixta: se añaden regresores uno a uno, pero en cada iteración se puede eliminar alguno si su p-valor excede un umbral</p></li>
</ul></li>
<li><p>No tienen criterio riguroso ni llevan a la misma solución. Además, se suelen utilizar en la misma muestra donde se estima</p></li>
</ul></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
