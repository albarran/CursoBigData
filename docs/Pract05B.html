<!DOCTYPE html>
<html>
<head>
  <title>Practica 05B - El proceso de modelización y tidymodels</title>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Practica 05B - El proceso de modelización y <code>tidymodels</code>',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: 'Pract05B_files/logo.svg',
              },

      // Author information
      presenters: [
            {
        name:  'Prof.: Pedro Albarrán' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            {
        name:  'Prof.: Alberto Pérez' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }
/* https://github.com/ropensci/plotly/pull/524#issuecomment-468142578 */
slide:not(.current) .plotly.html-widget{
  display: block;
}

    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
            code.sourceCode > span { display: inline-block; line-height: 1.25; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode { white-space: pre; position: relative; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    code.sourceCode { white-space: pre-wrap; }
    code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
        
    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(Pract05B_files/logo.svg) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>


</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="Pract05B_files/logo.svg"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      
      <p data-config-presenter><!-- populated from slide_config.json --></p>
            <p style="margin-top: 6px; margin-left: -2px;">Universidad de Alicante, Curso 2020/21</p>
          </hgroup>
  </slide>

<slide class=""><hgroup><h2><code>Tidymodels</code></h2></hgroup><article  id="tidymodels">

<ul>
<li><p><code>tidymodels</code> es una colección de paquetes para el <strong>proceso de modelización</strong> (NO implementa modelos) <!--en aprendizaje automático--> con los principios de <code>tidyverse</code></p>

<ul>
<li>pre-procesamiento de datos</li>
<li>la validación de resultados.</li>
</ul></li>
</ul>

<center>

<img width="70%" src='pic/tidymodels.png' title=''/>

</center>

</article></slide><slide class=""><hgroup><h2>Proceso de modelización</h2></hgroup><article  id="proceso-de-modelización">

<pre class = 'prettyprint lang-r'>install.packages(&quot;tidymodels&quot;)</pre>

<pre class = 'prettyprint lang-r'>library(tidymodels)</pre>

<center>

<img width="90%" src='pic/tidymodels_process.png' title=''/>

</center>

<!--
* `recipes`: preprocesado de datos

* `rsample`: validar modelos (ej., validación cruzada)

* `parsnip`: definición de modelos.

* `yardstick`: para calcular métricas de modelos.

-->

<ul>
<li><p>Las acciones del proceso <!--(preparación de datos, entrenamiento del modelo, validación, ...)--> no se ejecutan directamente: primero se define cada paso y se ejecutan todos al final</p></li>
<li><p><code>workflows</code>: combinar todos los pasos anteriores en un único objeto</p></li>
</ul>

<!--
* Otras librerías de `tidymodels`: `dials` (manejar hiperparámetros), `tune` (afinar modelos)
-->

<ul>
<li>Otros paquetes &ldquo;similares&rdquo; a <code>tidymodels</code>: <code>mlr3</code>, <code>caret</code>, <code>H2O</code></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Pre-procesado</h2></hgroup><article  id="pre-procesado">

<ul>
<li><p>Con <code>dplyr</code> (<code>tidyverse</code>) se pueden <strong>transformar los datos</strong> para que sean adecuados para la modelización, pero <code>tidymodels</code> facilita algunas partes del proceso cuando el desarrollo del modelo es complejo</p></li>
<li><p><code>initial_split()</code>: particionar los datos en prueba y entrenamiento.</p></li>
</ul>

<pre class = 'prettyprint lang-r'>library(mosaicData)
set.seed(9753)
RailTrail_part &lt;- RailTrail %&gt;% initial_split(prop = .8)</pre>

<!-- Ver el objeto -->

<ul>
<li>Más flexibilidad y opciones que la partición con <code>sample_frac()</code> (ver ayuda)</li>
</ul>

<!-- Ej. strata -->

<ul>
<li>Las funciones <code>training()</code> y <code>testing()</code> acceden a cada submuestra</li>
</ul>

<pre class = 'prettyprint lang-r'>RailTrail_entren &lt;- RailTrail_part %&gt;% training()
RailTrail_prueb  &lt;- RailTrail_part %&gt;% testing()
intersect(RailTrail_entren, RailTrail_prueb)</pre>

</article></slide><slide class=""><hgroup><h2>Pre-procesado: recetas</h2></hgroup><article  id="pre-procesado-recetas">

<ol>
<li><p><code>recipe()</code>: define transformaciones a aplicar.</p></li>
<li><p><code>prep()</code>: ejecuta transformaciones sobre unos datos <!--(típicamente, los datos de entrenamiento)--></p></li>
</ol>

<ul>
<li><code>recipe()</code> es &ldquo;similar&rdquo; a <code>ggplot()</code>: su principal argumento es una <em>fórmula</em> (define el rol de las variables) y se van añadiendo <em>pasos</em> con <code>step_</code>

<ul>
<li><code>step_corr()</code>: elimina variables con alta correlaciones con otras</li>
<li><code>step_scale()</code>: rescala variables numéricas a desviación estándar de uno</li>
</ul></li>
</ul>

<!--    
    + `step_center()`: normaliza datos numéricos para tener media cero

    + step_rm()

Ver ayuda de recipes, ej. recipes::Roles
-->

<ul>
<li><p>Los pasos se aplican a una sola variable, a todas o a un subconjunto con <code>all_outcomes()</code>, <code>all_predictors()</code>, <code>all_numeric()</code>, <code>all_nominal()</code>, <code>contains()</code>, etc.</p>

<ul>
<li><code>step_dummy(all_predictors(), -all_numeric())</code></li>
</ul></li>
</ul>

<!--
    + `step_corr(all_predictors())` <!--solo aplica `step_corr()` a regresores-->

<ul>
<li>También hay pasos de control como <code>check_missing()</code></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Pre-procesado: recetas (cont.)</h2></hgroup><article  id="pre-procesado-recetas-cont.">

<ul>
<li>Se combina todo en un objeto de receta y se prepara (<code>prep()</code>)</li>
</ul>

<pre class = 'prettyprint lang-r'>receta_lm1 &lt;- training(RailTrail_part) %&gt;%            # Datos: NO crucial
  recipe(volume ~ cloudcover + precip + avgtemp) %&gt;%
  step_poly(avgtemp, degree = 6) %&gt;% 
  step_corr(all_predictors(), threshold = 0.9) %&gt;%
  step_center(all_predictors(), -all_nominal()) %&gt;%
  step_scale(all_numeric(), -all_outcomes())
receta_lm1_prep &lt;- receta_lm1 %&gt;%  prep()</pre>

<!-- los datos de la receta NO son importantes: se definirán al usarla luego -->

<ul>
<li>Los datos procesados en la receta se extraen con <code>juice()</code></li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_entrena &lt;- receta_lm1_prep %&gt;% juice()</pre>

<!-- ver que los datos tienen media cero y varianza 1 -->

<ul>
<li>El preprocesado se aplica a otros datos con <code>bake()</code></li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_prueba &lt;- receta_lm1_prep %&gt;% bake(testing(RailTrail_part))</pre>

</article></slide><slide class=""><hgroup><h2>Entrenamiento del modelo</h2></hgroup><article  id="entrenamiento-del-modelo">

<ul>
<li><p>Varios paquete de R estiman el mismo tipo de modelo, con su propia interfaz y argumentos: ej., una regresión lineal con <code>lm</code> y con <code>glmnet</code></p></li>
<li><p><code>tidymodels</code> define un modelo con las mismas funciones y argumentos</p></li>
</ul>

<ol>
<li><p>Tipo de modelo: ej., <code>linear_reg()</code> para cualquier regresión lineal</p>

<ul>
<li>siempre el mismo nombre de argumentos para los paquetes que lo usen y los llaman de forma distinta</li>
</ul></li>
<li><p>Se determina el paquete de R con <code>set_engine()</code></p></li>
<li><p>Finalmente se ejecuta el modelo con <code>fit()</code> cuyos argumentos son</p>

<ul>
<li>una fórmula</li>
<li>los datos de entrenamiento <!--(sacados de `juice()`)--></li>
</ul></li>
</ol>

</article></slide><slide class=""><hgroup><h2>Entrenamiento del modelo (cont.)</h2></hgroup><article  id="entrenamiento-del-modelo-cont.">

<pre class = 'prettyprint lang-r'>modelo_lm1     &lt;- linear_reg(mode= &quot;regression&quot;, penalty = 0) %&gt;%
                    set_engine(&quot;lm&quot;) 
modelo_lm1_est &lt;- modelo_lm1 %&gt;% 
                    fit(volume ~ ., data = lm1_entrena)</pre>

<ul>
<li>Podemos reutilizar la receta con otro paquete</li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_glmnet1     &lt;- linear_reg(penalty = 0) %&gt;% 
                        set_engine(&quot;glmnet&quot;) %&gt;% 
                        set_mode(&quot;regression&quot;)
modelo_glmnet1_est &lt;- modelo_glmnet1 %&gt;% 
                        fit(volume ~ ., data = lm1_entrena)</pre>

<ul>
<li>El modelo se define en pequeños pasos en lugar de una única función con muchos argumentos (más flexible y fácil de aprender)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Entrenamiento del modelo: resultados</h2></hgroup><article  id="entrenamiento-del-modelo-resultados">

<ul>
<li>Para presentar los resultados de la estimación en formato de <code>tibble</code> se utiliza <code>broom::tidy()</code></li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_lm1_est %&gt;% broom::tidy()</pre>

<ul>
<li>Podemos obtener otros detalles de la estimación con <code>glance()</code></li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_lm1_est %&gt;% broom::glance()</pre>

<ul>
<li>Finalmente, <code>augment()</code> puede ser usado para obtener predicciones del modelo, residuos, etc.</li>
</ul>

<pre class = 'prettyprint lang-r'>augment(modelo_lm1_est$fit) %&gt;% select(volume, .fitted:.std.resid)</pre>

</article></slide><slide class=""><hgroup><h2>Entrenamiento del modelo: clasificación</h2></hgroup><article  id="entrenamiento-del-modelo-clasificación">

<pre class = 'prettyprint lang-r'>censo &lt;- read_csv(&quot;https://www.dropbox.com/s/6bqyjnkd2c638rm/census.csv?dl=1&quot;) 
set.seed(7482)
censo_part &lt;- censo %&gt;% initial_split(prop = .8)

receta_logit1 &lt;- training(censo_part) %&gt;%
  recipe(income ~ age + education + race + sex + capital_gain)

receta_logit1_prep &lt;- receta_logit1 %&gt;%  prep()

logit1_entrena &lt;- receta_logit1_prep %&gt;% juice()
logit1_prueba  &lt;- receta_logit1_prep %&gt;% bake(testing(censo_part))

modelo_logit1 &lt;- logistic_reg(mode= &quot;classification&quot;, penalty = 0) %&gt;%
                    set_engine(&quot;glm&quot;)

modelo_logit1_est &lt;- modelo_logit1 %&gt;% 
                        fit(income ~ ., data = logit1_entrena)
modelo_logit1_est %&gt;% broom::tidy()</pre>

</article></slide><slide class=""><hgroup><h2>Predicción</h2></hgroup><article  id="predicción">

<ul>
<li><p>La función <code>predict()</code> en <code>parsnip</code> predice valores numéricos, clases, probabilidad de cada categoría, intervalos de confianza, etc.</p>

<ul>
<li>por defecto, según el modo de modelo (tipo de variable de respuesta) o fijándolo explícitamente</li>
</ul></li>
<li><p>Devuelve un <code>tibble</code> (no un vector), lo que permite añadir la predicción a los datos originales con <code>bind_cols()</code></p></li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_lm1_est %&gt;% predict(new_data = lm1_prueba) %&gt;% 
  bind_cols(lm1_prueba) %&gt;%  glimpse()                # Variable predicha .pred

modelo_logit1_est %&gt;% 
  predict(logit1_prueba) %&gt;% glimpse()     # clase predicha .pred_class

modelo_logit1_est %&gt;% 
  predict(logit1_prueba, type = &quot;prob&quot;) %&gt;% 
  glimpse()                                 # probabilidades de cada categoría</pre>

</article></slide><slide class=""><hgroup><h2>Flujos de trabajo: <code>workflow()</code></h2></hgroup><article  id="flujos-de-trabajo-workflow">

<ul>
<li>Combina preprocesado y entrenamiento en un único objeto de flujos</li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_flujo &lt;- workflow() %&gt;%
  add_recipe(receta_lm1) %&gt;%       # add_formula() si no procesamos los datos
  add_model(modelo_lm1)</pre>

<ul>
<li>Se <code>prep()</code>ara la receta y entrena el modelo en una única llamada de <code>fit()</code></li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_flujo_est &lt;- lm1_flujo %&gt;% fit(data = RailTrail_part %&gt;% training()) </pre>

<ul>
<li>Este objeto contiene tanto la receta preparada como el modelo estimado</li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_flujo_est %&gt;% pull_workflow_prepped_recipe()  # aprox. receta_lm1_prep
lm1_flujo_est %&gt;% pull_workflow_fit()             # = modelo_lm1_est

lm1_flujo_est %&gt;% pull_workflow_fit() %&gt;% tidy()  # o glance() o # augment() </pre>

</article></slide><slide class=""><hgroup><h2>Flujos de trabajo: <code>workflows()</code> (cont.)</h2></hgroup><article  id="flujos-de-trabajo-workflows-cont.">

<ul>
<li>Los objetos de flujos se pueden usar para predecir o procesar datos</li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_flujo_est %&gt;% predict(RailTrail_entren)
lm1_flujo_est %&gt;% predict(RailTrail_prueb)

lm1_flujo_est  %&gt;% pull_workflow_prepped_recipe() %&gt;% bake(RailTrail_prueb)
lm1_flujo_est  %&gt;% pull_workflow_prepped_recipe() %&gt;% bake(RailTrail_entren)
# lm1_flujo_est  %&gt;% pull_workflow_prepped_recipe() %&gt;% juice()</pre>

<!-- juice() necesitaría otra opción adicional -->

<ul>
<li>Los flujos de trabajo existentes se modifican con <code>update_recipe()</code> / <code>update_model()</code>, <code>remove_recipe()</code> / <code>remove_model()</code>, <code>add_formula()</code> / <code>update_formula()</code>, etc.</li>
</ul>

<pre class = 'prettyprint lang-r'>lm2_flujo &lt;- lm1_flujo %&gt;% 
                update_recipe( receta_lm1 %&gt;% 
                    step_log(volume, skip=TRUE)  )</pre>

</article></slide><slide class=""><hgroup><h2>Validación del Modelo</h2></hgroup><article  id="validación-del-modelo">

<ul>
<li><code>metrics()</code> proporciona (automáticamente) las métricas a partir de un <code>tibble</code> con el valor observado (<em>truth</em>) y el predicho (<em>estimate</em>)</li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_flujo_est %&gt;% predict(RailTrail_prueb) %&gt;% 
  bind_cols(RailTrail_prueb) %&gt;%  
  metrics(truth=volume, estimate= .pred)         #   mae(truth=volume, estimate= .pred)</pre>

<ul>
<li>Se puede obtener varias métricas de forma separada con <code>mae()</code>, <code>rmse()</code>, etc. o definir las que queremos con <code>metric_set()</code> (ver más adelante)</li>
</ul>

<!-- ver ayuda de p.e. rsq() y accuracy() para ver las disponibles -->

<ul>
<li><p>La interfaz unificada de <code>tidymodels</code> permite medir las mismas métricas para otro modelo con mínimos cambios <!--cambiando el objeto del modelo--></p>

<ul>
<li>otro preprocesado (distintas variables, transformaciones)</li>
<li>otro método de estimación, etc</li>
</ul></li>
<li><p>¿Cuáles serían para un modelo con la variable dependiente en logaritmos?</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Validación del Modelo: Clasificación</h2></hgroup><article  id="validación-del-modelo-clasificación">

<ul>
<li>Con la predicción de clases, se puede obtener la matriz de confusión</li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_logit1_est %&gt;% predict(logit1_prueba) %&gt;% 
  bind_cols(logit1_prueba) %&gt;%  
  conf_mat(truth=income, estimate= .pred_class)</pre>

<ul>
<li>Y varias métricas derivadas</li>
</ul>

<pre class = 'prettyprint lang-r'>mis_metricas &lt;- metric_set(accuracy, spec, sens)
modelo_logit1_est %&gt;% predict(logit1_prueba) %&gt;% 
  bind_cols(logit1_prueba) %&gt;%
  mis_metricas(truth=income, estimate= .pred_class)</pre>

<ul>
<li>Nota: para predecir clases se utiliza por defecto la clase con mayor probabilidad predicha (la más probable); es decir, en el caso binario un umbral de \(\small 0.5\)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Validación del Modelo: Clasificación (cont.)</h2></hgroup><article  id="validación-del-modelo-clasificación-cont.">

<ul>
<li>Si predecimos probabilidades, se pueden obtener la curva ROC y la AUC</li>
</ul>

<pre class = 'prettyprint lang-r'>logit1_probs &lt;- modelo_logit1_est %&gt;% predict(logit1_prueba, type = &quot;prob&quot;) %&gt;%
                      bind_cols(logit1_prueba) 

logit1_probs %&gt;%
  roc_curve(income, `.pred_&lt;=50K`) %&gt;%  autoplot()</pre>

<pre class = 'prettyprint lang-r'>logit1_probs %&gt;%
  roc_auc(income, `.pred_&lt;=50K`) </pre>

<!--
o la curvas de ganancias

```r
logit1_probs %>%
  gain_curve(income, `.pred_<=50K`) %>%
  autoplot()
```
-->

<ul>
<li>Se pueden combinar clases y probabilidades predichas</li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_logit1_est %&gt;% predict(logit1_prueba) %&gt;% 
  bind_cols(logit1_prueba) %&gt;%  
  bind_cols(logit1_probs %&gt;% select(1:2)) %&gt;% 
  metrics(truth=income, `.pred_&lt;=50K`, estimate= .pred_class)</pre>

</article></slide><slide class=""><hgroup><h2>Validación del Modelo: Clasificación con más de dos clases</h2></hgroup><article  id="validación-del-modelo-clasificación-con-más-de-dos-clases">

<ul>
<li><p>Se predice la probabilidad de cada clase</p></li>
<li><p>La clase predicha es la más frecuente</p></li>
<li><p>La matriz de confusión se obtiene de manera similar, pero sus dimensiones son \(\small k \times k\)</p></li>
<li><p>La <em>accuracy</em> sigue teniendo la misma interpretación</p></li>
<li><p>Paras la curva ROC y la AUC</p>

<ul>
<li>se incluyen las probabilidades predichas de todas las clases</li>
<li>se obtien una curva ROC y su AUC para cada clase</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Validación cruzada (VC)</h2></hgroup><article  id="validación-cruzada-vc">

<ul>
<li><p>Las particiones para VC se realizan en la <strong>muestra de entrenamiento</strong></p></li>
<li><p>De forma similar a la división de entrenamiento/prueba, un subconjunto de los datos se utiliza para analizar el modelo y otro diferente para evaluarlo</p></li>
</ul>

<center>

<img width="65%" src='pic/resampling.svg' title=''/>

</center>

</article></slide><slide class=""><hgroup><h2>El proceso de validación cruzada</h2></hgroup><article  id="el-proceso-de-validación-cruzada">

<ul>
<li><p><code>vfold_cv()</code> crea particiones en los datos de entrenamiento sin procesar</p>

<ul>
<li>ver ayuda para opciones adicionales (ej. <em>estratos</em>)</li>
</ul></li>
</ul>

<pre class = 'prettyprint lang-r'>set.seed(9753)
RailTrail_cv &lt;- RailTrail_entren %&gt;% vfold_cv(v=10)</pre>

<ul>
<li>El objeto de validación cruzada contiene cada una de los 10 grupos</li>
</ul>

<pre class = 'prettyprint lang-r'>RailTrail_cv</pre>

<ul>
<li>Se puede acceder a los datos de entrenamento y prueba de cada uno de ellos con <code>analysis()</code> y <code>assessment()</code>, respectivamente</li>
</ul>

<pre class = 'prettyprint lang-r'>RailTrail_cv$splits[[1]] %&gt;% analysis() %&gt;% dim()
RailTrail_cv$splits[[1]] %&gt;% assessment() %&gt;% dim()</pre>

</article></slide><slide class=""><hgroup><h2>El proceso de validación cruzada (cont.)</h2></hgroup><article  id="el-proceso-de-validación-cruzada-cont.">

<ul>
<li><code>fit_resamples()</code>, similar a <code>fit()</code>, sobre un flujo de trabajo ya definido …</li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_flujo_cv_est &lt;- lm1_flujo  %&gt;% 
                        fit_resamples(RailTrail_cv)</pre>

<ul>
<li>… crea un objeto con los valores de las métricas</li>
</ul>

<pre class = 'prettyprint lang-r'>lm1_flujo_cv_est %&gt;% collect_metrics()      # promedio sobre 10 iteraciones
lm1_flujo_cv_est$.metrics %&gt;% bind_rows()   # valores en cada iteración</pre>

<ul>
<li>Se pueden cambiar varias opciones del proceso</li>
</ul>

<!-- como las métricas calculadas y otros elementos de control -->

<pre class = 'prettyprint lang-r'>lm1_flujo_cv_est &lt;- lm1_flujo  %&gt;% 
                        fit_resamples(
                          resamples = RailTrail_cv, 
                          metrics   = metric_set(rmse, mae),
                          control   = control_resamples(save_pred = TRUE)
                        )</pre>

</article></slide><slide class=""><hgroup><h2>Selección de hiperparámetros: <em>tuning</em></h2></hgroup><article  id="selección-de-hiperparámetros-tuning">

<ul>
<li><p>Algunos parámetros, denominados <strong>hiperparámetros</strong>, no pueden aprenderse directamente durante el entrenamiento del modelo (ej., \(\small \lambda\) en LASSO)</p></li>
<li><p>Proceso de <strong>ajuste</strong> (<em>tuning</em>): se estima el mejor valor entrenando muchos modelos y explorando su funcionamiento mediante validación cruzada</p></li>
<li><p>Al definir el modelo, se identifican los hiperparámetros a ajustar</p></li>
</ul>

<pre class = 'prettyprint lang-r'>modelo_LASSO &lt;- linear_reg(mode= &quot;regression&quot;, 
                           penalty = tune() ) %&gt;%
                    set_engine(&quot;glmnet&quot;) </pre>

<ul>
<li>Se establecen las combinaciones de valores sobre las que se buscará con <code>grid_random()</code>, <code>grid_max_entropy()</code> o <code>grid_regular()</code></li>
</ul>

<pre class = 'prettyprint lang-r'>LASSO_grid &lt;- grid_regular(penalty(range = c(0, 15), trans = NULL),     # rango
                          levels = 50)                     # número de valores</pre>

<!--

Tres estrategias 

* `grid_regular()` : combinaciones están igualmente espaciadas para cada hiperparámetro 

* `grid_random()` :  los valores son aleatorios dentro de unos límites preestablecidos

* `grid_max_entropy()`: los valores son aleatorios pero intentan cubrir todo lo posible el espacio de búsqueda

-->

</article></slide><slide class=""><hgroup><h2>Flujo de trabajo para <em>tuning</em></h2></hgroup><article  id="flujo-de-trabajo-para-tuning">

<ul>
<li>Se define el flujo de trabajo</li>
</ul>

<pre class = 'prettyprint lang-r'>flujo_LASSO_tuning &lt;- workflow() %&gt;%
  add_recipe(receta_lm1) %&gt;% 
  add_model(modelo_LASSO)</pre>

<ul>
<li>Se usa <code>tune_grid()</code> de forma a similar a <code>fit_resamples()</code></li>
</ul>

<!-- alternativa: tune_bayesian() -->

<pre class = 'prettyprint lang-r'>LASSO_tuned &lt;- flujo_LASSO_tuning %&gt;% 
                tune_grid(
                  resamples = RailTrail_cv, 
                  metrics   = metric_set(rmse, mae),
                  grid      = LASSO_grid
                )</pre>

<ul>
<li>NOTA: tanto valicación cruzada como el proceso de <em>tuning</em> son computacionalmente intensivos por lo que se suelen realizar mediante computación en paralelo</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Resultados del ajuste</h2></hgroup><article  id="resultados-del-ajuste">

<ul>
<li>Podemos explorar visualmente los resultados del ajuste y seleccionar el mejor resultado</li>
</ul>

<pre class = 'prettyprint lang-r'>penalty &lt;- LASSO_tuned %&gt;% collect_metrics() %&gt;% filter(.metric == &quot;rmse&quot;)

penalty %&gt;% ggplot(aes(x=penalty, y=mean)) + 
              geom_line() + geom_point(color=&quot;red&quot;) + 
              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=&quot;gray&quot;) +
              scale_x_log10() </pre>

<ul>
<li>Podemos ver los cinco mejores candidatos o el mejor de todos</li>
</ul>

<pre class = 'prettyprint lang-r'>LASSO_tuned %&gt;% show_best(&quot;rmse&quot;)
mejor_lambda &lt;- LASSO_tuned %&gt;% select_best(&quot;rmse&quot;)</pre>

</article></slide><slide class=""><hgroup><h2>Finalizando el modelo</h2></hgroup><article  id="finalizando-el-modelo">

<ul>
<li>Podemos actualizar el flujo de trabajo con los valores de <code>select_best()</code></li>
</ul>

<pre class = 'prettyprint lang-r'>flujo_final &lt;- flujo_LASSO_tuning %&gt;% 
                 finalize_workflow(mejor_lambda)</pre>

<ul>
<li>Y ver los resultados de este modelo en los datos completos de entrenamiento</li>
</ul>

<pre class = 'prettyprint lang-r'>flujo_final %&gt;%  fit(data = RailTrail_entren) %&gt;%  broom::tidy()</pre>

<ul>
<li>Finalmente, podemos usar <code>last_fit()</code>: ajusta al modelo finalizado en los datos de entrenamiento y lo evalúa en los de prueba.</li>
</ul>

<pre class = 'prettyprint lang-r'>final_fit &lt;- flujo_final %&gt;% last_fit(RailTrail_part)

final_fit %&gt;% collect_metrics()
final_fit %&gt;% collect_predictions()</pre></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
