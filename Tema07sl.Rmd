---
#subtitle: "Técnicas para 'Big Data' en Economía"
#subtitle: "Muestreo y Análisis de Datos"
title    :  "Tema 07 - Fundamentos Estadísticos"
author: 
  - "Prof.: Pedro Albarrán"
  - "Prof.: Alberto Pérez"
job: "Universidad de Alicante" 
date: "Universidad de Alicante, Curso 2020/21"  
output:
#  html_document:
#    toc: true
#    toc_float: true
  ioslides_presentation: 
    widescreen: yes
    logo: pic/by-nc-sa.eu.svg
#  html_document: default
#  beamer_presentation: 
#      slide_level: 2
#widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, eval = TRUE, echo = TRUE, results = "hide", fig.show="hide")

library(tidyverse)
library(dlookr)
#setwd("/home/albarran/Dropbox/MAD/00.TEC")
library(rmarkdown)
#render("filename.Rmd")     
#browseURL("filename.html")
```

## Fundamentos Estadísticos

- Objetivo: extraer información de los datos.

<center>
![](pic/model.png)
</center>

- Herramientas previas:
     * Limpieza y Transformación
     * Detectar patrones iniciales
     
- Métodos estadísticos, incluyendo **modelización**
     - Encontrar patrones complejos, y cuantifificar su fortaleza
     - Interpretación de datos


## Muestras y Poblaciones

* Los datos (casos observados) son una *muestra* de una *población* mayor (de casos potenciales)

<center>
![](pic/sample-pop2.png){width=82%}
</center>


## Muestreo de la población

```{r, echo=FALSE, eval=FALSE}
library(fitdistrplus)
library("actuar")

fw <- fitdist(SF$arr_delay+87, "weibull")
fg <- fitdist(SF$arr_delay+87, "gamma")
fln <- fitdist(SF$arr_delay+87, "lnorm")
fP <- fitdist(SF$arr_delay+87, "Pareto")

summary(bootdist(fln, niter = 1001))

par(mfrow = c(2, 2))
plot.legend <- c("Weibull", "lognormal", "gamma", "Pareto")
denscomp(list(fw, fln, fg, fP), legendtext = plot.legend)
qqcomp(list(fw, fln, fg, fP), legendtext = plot.legend)
cdfcomp(list(fw, fln, fg, fP), legendtext = plot.legend)
ppcomp(list(fw, fln, fg, fP), legendtext = plot.legend)

library(dlookr)
SF %>% describe(arr_delay)
SF %>% mutate(lretraso=log(arr_delay+87)) %>%  normality(lretraso)
```

* Sabiendo el retraso medio desde NY a San Francisco (SFO) podemos  planificar la antelación con que se toma el vuelo

* Suponemos que la muestra total observada en `nycflights13` ha salido de una población teórica de una distribución lognormal:

```{r}
library(nycflights13)
SF <- flights %>%
  filter(dest == "SFO", !is.na(arr_delay))

SF %>%  
  ggplot() + geom_histogram(aes(x=arr_delay, y=..density..)) +
             geom_line(aes(x = arr_delay, 
                           y = dlnorm(SF$arr_delay+87, 4.403,0.409)
                           ))
```



## Decisiones basadas en datos observados

* Disponemos de una muestra con información de solo $n=25$ vuelos

```{r}
set.seed(501) # set.seed(501)  set.seed(1001) 
datos1 <- tibble(x = (rlnorm(n = 25, meanlog = 4.403, sdlog = 0.409) - 87) ) 
x <- datos1 %>% summarize(med=mean(x), sd = sd(x))
x
```


```{r, eval=FALSE, echo=FALSE}
datos1 %>% ggplot() + geom_histogram(aes(x=x, y=..density..))
datos1 %>% describe() %>% select(mean, sd, p00, p25, p50, p75, p100)
```

<!--
- `set.seed()` para especificar cómo imitar la selección aleatoria mediante *generador pseudo-aleatorio*.
-->


* Regla: bajo normalidad, sólo el 2,27% se retrasan más que $\mu + 2\sigma$:

```{r, eval=FALSE, echo=FALSE} 
SF %>% 
  summarize(prop.late1 = mean(arr_delay > 5.311 + 2 *	24.780),	
            prop.late2 = mean(arr_delay > 7.933 + 2 *	43.943))	
```

```{r, eval=FALSE, echo=FALSE} 
list((5.311 + 2 * 24.780) + 87, 
     (7.933 + 2 * 43.943) + 87) %>%  
  map_dbl(plnorm, meanlog = 4.403, sdlog = 0.409, lower.tail = FALSE)
```

```{r} 
plnorm( (x$med + 2 * x$sd) , meanlog = 4.403, sdlog = 0.409, lower.tail = FALSE)
```


1. ¿Era el supuesto apropiado? 

2. Condicionar a día, hora, aerolínea

3. ¿Qué sabemos sobre la incertidumbre en la estimación de $\mu$ y $\sigma$?

## Incertidumbre por la distribución del muestreo

* ¿Cómo de fiable es un estadístico muestral? Simulemos la distribución de la media en muchas muestras todas de tamaño $n=25$

```{r}
Muestras <- list()
set.seed(101)
for(i in 1:100){
  Muestras[[i]] <- tibble(x = rlnorm(n = 25, meanlog = 4.403, sdlog = 0.409) - 87)  %>% 
        summarize(media = mean(x), sd = sd(x))
}
Muestras_df <- Muestras %>% bind_rows()
Muestras_df
```


* Existe una gran variabilidad del estadístico muestral: es poco fiable

* En una situación realista (solo tenemos UNA MUESTRA), ¿es posible **cuantificar la incertidumbre**?


## Distribuciones muestrales

* Un *estadístico* es un valor calculado a partir de una muestra (ej., la media)

* **Distribución muestral** es la distribución del estadístico en las muestras potenciales de **tamaño muestral $n$**
    +  si conocemos las distribución poblacional que genera las muestras, podemos disponer de muestras y ver cómo varía el valor del estadístico
    
<!--    + aquí lo hemos aproximado con 100 muestras -->

```{r}
Muestras %>% bind_rows() %>% ggplot(aes(x=media)) + geom_density()
```

* Por supuesto, nos interesan varios aspectos de la distribución muestral como su *forma* y *error estándar* (<!--desviación típica (variabilidad)--> variabilidad de la distribución muestral)

* El *intervalo de confianza del 95%* es otra forma de resumir la distribución muestral
    
```{r}
mean(Muestras_df$media) + sd(Muestras_df$media) * 1.96 * c(-1,1) 
```


## Distribuciones muestrales (cont.)

<!--
* La fiabilidad de un estadístico muestral se mide  por 

  1. la media del estadístico (media de la distribución muestral): debe estar cerca del verdadero (en la población). 

  2. el error estándar del estadístico (error estándar de la distribución muestral); debe ser pequeño. 
-->
* ¿Cómo cambia la media y el error estándar del estadístico cuando varia el tamaño muestral?

```{r}
Muestras_porN <- list()
nvec <- c(25, 50, 100, 200)
for(j in seq_along(nvec)){
  n <- nvec[j]
  Muestras <- list()   # bucle anterior, generalizando n y conservándolo en summarize
  set.seed(101)
  for(i in 1:100){
    Muestras[[i]] <- tibble(x = rlnorm(n = n, meanlog = 4.403, sdlog = 0.409) - 87)  %>%   
        summarize(media = mean(x), sd = sd(x), n = n)      
  }
  Muestras_porN[[j]] <- Muestras %>% bind_rows()
}
Muestras_Final <- Muestras_porN %>% bind_rows()
```


## Distribuciones muestrales: LGN y TCL

```{r}
Muestras_Final %>% ggplot(aes(x=media)) + geom_density() + facet_wrap(~n)
Muestras_Final %>% group_by(n) %>% 
  summarize(media_de_media = mean(media), error = sd(media))
```

- *Ley de números grandes*: para un tamaño de la muestra $n$ grande, el promedio de la muestra está cerca de la media de la población <!--, y el error estándar es pequeño. -->

- *Teorema de Límite Central*: para un tamaño de la muestra $n$ grande, la distribución muestral de la media es normal.

* $\mbox{Error estándar}(\bar{X}_n) = \frac{\sigma}{\sqrt{n}},$
    donde $\sigma$ es la desviación estándar de la población. 

    * Si **aumentamos el tamaño de la muestra en $n$, el error estándar disminuirá**.


## Procedimiento *Bootstrap* 

<!-- * En la práctica, sólo tenemos UNA muestra de tamaño $n$ (no la población) -->

* **Idea**: pensar en la ÚNICA muestra como si fuera la población 

1. Tomar muchas nuevas muestras (*remuestras* o muestras de Bootstrap) con reemplazamiento de la muestra original

    *  Ej.: para $(1,2,3)$ incluye los casos $(1,1,2)$, $(1,1,3)$, $(2,2,1)$, etc.
  
    * ${n\choose n}= (n + n - 1)!/(n! (n-1)!)$ remuestras: la muestra original es una combinación entre muchas

2. En cada remuestra, se puede calcular cualquier estadístico 
    
* Se obtiene la **distribución muestral bootstrap**: NO es la distribución muestral, pero aproxima sus aspectos principales (ej., *error estándar*).

<!--una distribución de valores de los ensayos bootstrap -->
<!-- aproxima para vlaores moderados de n -->

* Puede aplicarse para cuantificar la incertidumbre de **casi cualquier estadístico** (media, varianzas, coeficientes de regresión, etc.)

<!-- es un método estadístico que nos  permite aproximar la distribución muestral sin acceso a la población.-->

## *Bootstrap* con $B = 1000$ para `datos1` 
```{r}
n <- nrow(datos1)
boot <- list() 
for(i in 1:1000){
    boot[[i]] <- datos1 %>% 
      sample_n(size = n, replace = TRUE) %>%
      summarize(media = mean(x))
  }
boot_df <- boot %>% bind_rows()
```
 
<!-- 
- `sample_n()`  para seleccion filas de forma *aleatoria* de una tabla,
-->

 
```{r}
boot_df %>% ggplot(aes(x = media)) + geom_density() # densidad bootstrap de la media
sd(boot_df$media)                                   # estimación bootstrap del error estándar
```

 
```{r, eval=FALSE, echo=FALSE}
boot_df %>% ggplot(aes(x = media)) + 
  geom_density() + 
  labs(title = "Distribución Bootstrap de la media de retraso en `datos1`")
```


<!--
* Aunque podemos obtener un mejor intervalo de confianza basado

```{r}
mean(boot_df$media) + c(-1,1) * 1.96 * sd(boot_df$media)
```
-->

* Sin suponer normalidad o TCL, se obtienen los percentiles del intervalo en la distribución muestral bootstrap:

```{r}
c(sort(boot_df$media)[25], sort(boot_df$media)[975])
```

<!--
#### Errores estándar Bootstrap para muestras grandes

El siguiente código toma muestras para la población `SF` sólo una vez para cada uno de los tamaños muestrales 25--200, y utiliza la muestra (sin referencia a la población) para estimar el error estándar. 

```{r}
Trials.bootstrap <-list()
nvec = c(25,50,100,200)
for(j in seq_along(nvec)){
  n <- nvec[j]
  sample_df <- SF %>% sample_n(size = n)
  Trials_n <- list() 
  for(i in 1:1000){
    Trials_n[[i]] <- sample_df %>% 
      sample_n(size = n, replace = TRUE) %>%
      summarize(mean = mean(arr_delay), n = n)
  }
  Trials.bootstrap[[j]] <- bind_rows(Trials_n)
}
bind_rows(Trials.bootstrap) %>% 
  group_by(n) %>% 
  summarize(error = sd(mean))
```

Estas estimaciones del error estándar, calculadas mediante bootstrapping de la muestra, se aproximan bastante el error estándar, calculado a partir de la población. 

En este ejemplo, el estadístico muestral es la media. En la práctica, los estadísticos de interés son más complejos, por ejemplo, la estimación del coeficiente en el modelo de regresión lineal. El procedimiento de bootsrapping se puede aplicar a casi todas las situaciones, para cuantificar la incertidumbre en un estadístico.
-->

## Modelización Condicional 

* La población NO suele ser *homogenea*.

* Los retrasos son más frecuentes a determinadas horas 

```{r}
SF %>%
  ggplot(aes(x = hour, y = arr_delay)) +
  geom_boxplot(aes(group = hour)) + geom_smooth(method = "lm")  +
  coord_cartesian(ylim = c(-30, 120))

mod1 <- lm(arr_delay ~ hour, data = SF)
broom::tidy(mod1)
```

* En particular, los grandes retrasos (superior a 60 minutos)
```{r}
SF %>% mutate(gran_retraso = arr_delay > 60) %>%
  ggplot(aes(x = hour, fill= gran_retraso)) + 
  geom_bar(position = "fill")                  # para representar frecuencia
```

## Modelización Condicional (cont.)

<!--
* También tenemos variación por mes, día de la semana, aeropuerto de origen, aerolínea, etc.
-->

* Un modelo de regresión permite incluir todas las **variables explicativas** de la variación de la variable dependiente

```{r echo=TRUE, eval=FALSE}
library(lubridate)
SF2 <- SF %>% 
  mutate(
    fecha  = as.Date(time_hour), 
    diasem = as.factor(wday(day, label = TRUE)),
    estaci = ifelse(month %in% 6:7, "verano", "otros meses")
  )

mod2 <- lm(arr_delay ~ hour + origin + carrier + as.factor(month) + dow, data = SF2)
broom::tidy(mod2)
```

* Para una variable de respuesta binaría como `gran_retraso` puede utilizar la *regresión logística* (logit)


## "Confounding factor" y Causalidad

* **"Correlación no implica causalidad"**, salvo en [ensayos científicos aleatorios](https://es.wikipedia.org/wiki/Prueba_controlada_aleatorizada) cuidadosamente controlados
  + en otros campos como marketing digital o analítica de web se denominan [pruebas A/B](https://es.wikipedia.org/wiki/Prueba_A/B) (ej. dos versiones de una misma web)

* En general (datos observacionales), nos preocupa que otros factores que puedan ser los verdaderos determinantes de la relación observada

* En los ensayos aleatorios se controla quien recibe una intervención (tratamiento) y quien no (control)

    + En promedio, todos los demás factores están equilibrados entre los dos grupos: las diferencias pueden atribuirse a la aplicación del tratamiento

    +  Pero si los sujetos no cumplen con los tratamientos o se pierden en el seguimiento...

## "National Supported Work Demonstration"
```{r}
url <- "http://www.nber.org/~rdehejia/data/"
nsw <- haven::read_dta(paste0(url,"nsw_dw.dta")) 
lm(data=nsw %>%  filter(black==1), re78 ~ treat ) %>% broom::tidy()
```

* Añadimos más datos observacionales

```{r}
nsw2 <- nsw %>% bind_rows(haven::read_dta(paste0(url,"psid_controls.dta"))) 
lm(data=nsw2 %>%  filter(black==1), re78 ~ treat ) %>% broom::tidy()
```

* El programa estaba dirigido a quienes previamente ganaban menos: 
```{r}
nsw2 <- nsw2 %>% mutate(rePre = (re74+re75)/2)
lm(data=nsw2 %>%  filter(black==1), rePre ~ treat ) %>% broom::tidy()
```

* ¿Y si mantenemos "constante" ese factor en `nsw2`? ¿Y en `nsw`? [Responder](https://docs.google.com/forms/d/e/1FAIpQLSfTdODmH2MIUuC00wJF9H89aLsQf4KQqDeZ71BgaaSferbn1Q/viewform)
```{r}
lm(data=nsw2 %>%  filter(black==1), re78 ~ treat + rePre) %>% broom::tidy()
```
<!--

* PREGUNTA: ¿cambia algo si controlamos por la renta previa usando los datos experimentales?

```{r}
nsw <- nsw %>% mutate(rePre = (re74+re75)/2)
lm(data=nsw2 %>%  filter(black==1), re78 ~ treat + rePre) %>% broom::tidy()
```

```{r, echo=FALSE, eval=FALSE}
nsw <- nsw %>% mutate(rePre = (re74+re75)/2)
lm(data=nsw %>%  filter(black==1), rePre ~ treat ) %>% broom::tidy()
```
-->

## Descuentos y ventas

```{r echo=FALSE, eval=FALSE}
clear 
set seed 404
set obs 404

gen tipo = int(_n/40)

gen discount = max(3.5*tipo + int(3*(uniform()-0.5)),0)

gen income=uniform()*(20-tipo*2)*1000+2000
gen renta_baja = income < 7500

gen sales=5390+4.4*income+544*discount+990*discount*!renta_baja+invnorm(uniform())*1500

drop tipo renta_baja
cd /home/albarran/Archivos/teaching/MAD/00.TEC/data
outsheet using discount.csv, delim(",") replace


reg sales discount
reg sales discount income

gen renta_baja = income < 7500
reg sales discount if renta_baja
reg sales discount if !renta_baja
```


```{r}
datos <- read_csv("https://www.dropbox.com/s/c91j0nvg51hwq89/discount.csv?dl=1")
```

* El porcentaje medio de descuentos afecta negativamente a las ventas

```{r}
datos %>% ggplot(aes(x=discount, y=sales)) + geom_point() + geom_smooth(method = "lm")
lm(data = datos, sales ~ discount) %>% broom::tidy()
```

* Pero si tenemos en cuenta la renta...

```{r}
datos %>% mutate(renta_baja = income < 7500) %>%  
  ggplot(aes(x=discount, y=sales)) + geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~renta_baja)
lm(data = datos, sales ~ discount + income) %>% broom::tidy()
```
